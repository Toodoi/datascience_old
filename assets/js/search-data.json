{
  
    
        "post0": {
            "title": "Kaggle Cassava Leaf Competition",
            "content": "This notebook briefly documents my final model for the Cassava Leaf Disease Classification competition currently on Kaggle. After building half a dozen models over the last two weeks I have achieved a maximum accuracy of 89.4% on the withheld test set. Although this accuracy is very similar to the current first place score of 90.5%, it is still a world a way in Kaggle competition terms. With this final model I hope to receive a small boost in accuracy by consolidating additional data I have found from a previous competition and will include a batch of unlabelled data. . Download and prepare the data . The competition dataset contains 21,397 images. To expand my dataset and attempt to make the model more accurate, I also downloaded an additional 5,600 labelled images from an old competition dataset. In addition to this, I found an extra 12,596 images of cassava leaves belonging to the same five classes as the competition dataset. To expand even further, I will first train a model on the labelled data and then use it for inference on the unlabelled set. Then I will take the images where the model predicted their class value with very high confidence and add them as additional pseudo-labelled data to the overall dataset. . url = &#39;https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/13836/1718836/compressed/train_images.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&amp;Expires=1607653419&amp;Signature=qVDAZiv7WLmZsHSua7PXj57fzvLpLWcDCKAHP%2BuVWvGfKUIiFoo1JZ6XZbK3Ro%2BKeSuisVoJlt5nkQAnyMX0vglWyTRSSaC%2BKwkKvjHBPVNeGtlNXLXGdixKMWePMUEgQXC1XCw8m70T3RdTxPr5NX0vi93DrhjDcciETULct%2B84akCwV551Eowsy5%2Fy%2FLXA%2FsqrIjSHnICA5O6C8eiQSDOEVsCUpNXN262mDIZ3CM3wAcx%2Fm00hyLEaNAmAlSRyr9Im7At6ORZbH2t71aET5oYWgoHcyEL280h1mOgrSVO%2F5L6cJaS4pE9m6DixJUa1J3NUBPjsfcaWjHGbJ%2BuNkg%3D%3D&amp;response-content-disposition=attachment%3B+filename%3Dtrain_images.zip&#39; wget.download(url, &#39;comp_train.zip&#39;) . &#39;comp_train.zip&#39; . !mkdir leaf !unzip comp_train.zip -d leaf/train . !unzip train2.zip -d leaf/train2 . path = Path(&#39;leaf&#39;) path.ls() . (#2) [Path(&#39;leaf/train&#39;),Path(&#39;leaf/train2&#39;)] . !unzip extraimages.zip -d leaf/extras . unlabelled_imgs = (path/&#39;extras/extraimages&#39;) unlabelled_imgs.ls() . (#12596) [Path(&#39;leaf/extras/extraimages/extra-image-13099.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-3716.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-14330.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-15689.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-14863.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-6811.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-11460.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-7662.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-14235.jpg&#39;),Path(&#39;leaf/extras/extraimages/extra-image-2074.jpg&#39;)...] . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . with open(&#39;/content/drive/My Drive/train.csv&#39;) as f: df = pd.read_csv(f) . df[&#39;image_id&#39;] = df[&#39;image_id&#39;].apply(lambda x: f&#39;train/{x}&#39;) df.head() . image_id label . 0 train/1000015157.jpg | 0 | . 1 train/1000201771.jpg | 3 | . 2 train/100042118.jpg | 1 | . 3 train/1000723321.jpg | 1 | . 4 train/1000812911.jpg | 3 | . map_classes = { &quot;0&quot;: &quot;cbb&quot;, &quot;1&quot;: &quot;cbsd&quot;, &quot;2&quot;: &quot;cgm&quot;, &quot;3&quot;: &quot;cmd&quot;, &quot;4&quot;: &quot;healthy&quot; } . df[&#39;class&#39;] = df[&#39;label&#39;].astype(str).map(map_classes) df = df.drop(columns=[&#39;label&#39;]) df.head(), df.shape . ( image_id class 0 train/1000015157.jpg cbb 1 train/1000201771.jpg cmd 2 train/100042118.jpg cbsd 3 train/1000723321.jpg cbsd 4 train/1000812911.jpg cmd, (21397, 2)) . base_train_pth = (path/&#39;train2/train&#39;) . dict_lst = [] for dir in base_train_pth.ls(): for file in dir.ls(): dir_name = file.parent.name f_path = str(file)[18:] clean_path = f_path[len(dir_name):] dict_lst.append({&#39;image_id&#39;: f&#39;train{clean_path}&#39;, &#39;class&#39;: f&#39;{dir_name}&#39;}) . Merging the two sets of labelled images, I now have 27,053 images to use for training. However I will use 15% of these images as a validation set to train the model. . df = df.append(dict_lst, True) df.shape . (27053, 2) . We can see from the graph below that the dataset is quite significantly imbalanced with cmd (Cassava Mosaic Disease) accounting for almost 16,000 images out of 27,053. However hopefully we have enough images of each type of disease for the CNN to learn enough features to make accurate predictions for each class. . sns.countplot(df[&#39;class&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe9fe42a278&gt; . I experimented a lot with different data augmentations on a subset of the data so I could quickly find which parameters were yielding better results. In the end I left most of the fastai aug_transforms function on default settings and found that blowing the image size up to 1200 and then random resize cropping down to 700 (which is around the average image size in the dataset) works well for good results. Flipping the images vertically reduced accuracy. . blocks = (ImageBlock, CategoryBlock) def get_x(r): return path/r[&#39;image_id&#39;] def get_y(r): return r[&#39;class&#39;] item_tfms = Resize(1200) batch_tfms = aug_transforms(size=700, max_lighting=0.2, flip_vert=False, max_rotate=15.0, min_scale=0.70) . main_block = DataBlock(blocks = blocks, splitter = RandomSplitter(valid_pct=0.15), get_x = get_x, get_y = get_y, item_tfms = item_tfms, batch_tfms = batch_tfms) . main_dls = main_block.dataloaders(df, bs=28) . main_dls.show_batch(max_n=6) . Training the first model . This model uses transfer learning with ResNet50 and uses cross entropy for the loss function. Fastai&#39;s fine_tune method trains the first epoch only on the randomly initialised layers that have been added to the pre-trained model and then &#39;unfreezes&#39; the other layers and continues training all layers for the remaining epochs. Here I trained for 8 epochs in total and recieved an accuracy of 89.69% on the validation set. . In my experience from training several models for this competition, the model generalises very well to the test set and the accuracy recieved when submitting to Kaggle is almost always the same as recieved on the validation set . main_learner = cnn_learner(main_dls, resnet50, metrics=accuracy).to_fp16() . Downloading: &#34;https://download.pytorch.org/models/resnet50-19c8e357.pth&#34; to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth . . main_learner.fine_tune(7) . epoch train_loss valid_loss accuracy time . 0 | 0.690630 | 0.588408 | 0.802317 | 19:00 | . epoch train_loss valid_loss accuracy time . 0 | 0.465602 | 0.415724 | 0.870348 | 22:28 | . 1 | 0.444149 | 0.432029 | 0.859502 | 22:13 | . 2 | 0.428360 | 0.421088 | 0.863446 | 22:25 | . 3 | 0.356730 | 0.366144 | 0.876510 | 22:16 | . 4 | 0.345323 | 0.356473 | 0.882672 | 22:39 | . 5 | 0.254021 | 0.333151 | 0.893517 | 22:43 | . 6 | 0.256352 | 0.331851 | 0.896968 | 22:26 | . Inference on the unlabelled data . Now I use the model I just trained to do inference on the extra unlabelled data. I spent some time looking through the images from the various data sources and they all seemed to be very similar. Given this, I assume my model will correctly label around 90% of the images from this new dataset. Because I plan to add these images to my current dataset for training a model, I need to minimise the amount of incorrectly labelled images as they will have a detrimental effect on the model&#39;s accuracy. . test_dls = main_dls.test_dl(unlabelled_imgs.ls()) . test_dls.show_batch(max_n=6) . preds, _ = main_learner.tta(dl=test_dls) . . df2 = pd.DataFrame(columns = [&#39;image_id&#39;, &#39;label&#39;, &#39;confidence&#39;]) . pred_vals = torch.max(preds, dim=-1) df2[&#39;label&#39;] = pred_vals.indices.numpy() df2[&#39;confidence&#39;] = pred_vals.values.numpy() . df2.head() . image_id label confidence . 0 NaN | 3 | 0.999529 | . 1 NaN | 2 | 0.854078 | . 2 NaN | 3 | 0.998108 | . 3 NaN | 3 | 0.968962 | . 4 NaN | 0 | 0.515554 | . pth_lst = [] for img_pth in unlabelled_imgs.ls(): pth_lst.append(str(img_pth)[24:]) . df2[&#39;image_id&#39;] = pth_lst . Now I have a new DataFrame with all the image names, labels and confidence scores for the unlabelled dataset. . df2.head(), df2.shape . ( image_id label confidence 0 extra-image-13099.jpg 3 0.999529 1 extra-image-3716.jpg 2 0.854078 2 extra-image-14330.jpg 3 0.998108 3 extra-image-15689.jpg 3 0.968962 4 extra-image-14863.jpg 0 0.515554, (12595, 3)) . cp -a ./leaf/extras/extraimages/. ./leaf/train/ . Most images were classified with a confidence of 90% or greater. I will try to be conservative and only take images that were classified with a confidence of 95% or greater. This means I won&#39;t be gaining as much extra data, but I can be more certain the data I am getting is accurate. . df2[&#39;confidence&#39;].plot.box() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fea101359e8&gt; . df3 = df2[df2[&#39;confidence&#39;]&gt;0.95].copy() df3.shape . (7513, 3) . df3[&#39;class&#39;] = df3[&#39;label&#39;].astype(str).map(map_classes) df3 = df3.drop(columns=[&#39;label&#39;, &#39;confidence&#39;]) df3.head(), df3.shape . df3[&#39;image_id&#39;] = df3[&#39;image_id&#39;].apply(lambda x: f&#39;extras/extraimages/{x}&#39;) df3.head() . final_data = df.append(df3) final_data . image_id class . 0 train/1000015157.jpg | cbb | . 1 train/1000201771.jpg | cmd | . 2 train/100042118.jpg | cbsd | . 3 train/1000723321.jpg | cbsd | . 4 train/1000812911.jpg | cmd | . ... ... | ... | . 12584 extras/extraimages/extra-image-11410.jpg | cmd | . 12586 extras/extraimages/extra-image-14282.jpg | cmd | . 12589 extras/extraimages/extra-image-11549.jpg | cgm | . 12592 extras/extraimages/extra-image-10956.jpg | cmd | . 12593 extras/extraimages/extra-image-2830.jpg | cmd | . 34566 rows × 2 columns . We can see that the new data is even more imbalanced with more than 6,000 of the 7,513 images being from the cmd (Cassava Mosaic Disease) class. This is likely due to the dataset being imbalanced to begin with like the other datasets but also from the model being the most confident in classifying the cmd class itself which leads to mostly cmd images getting through the 95% threshold test. Unfortunately this probably means that the new data will not be too much help, but we will continue anyway. . sns.countplot(df3[&#39;class&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fe9fe3864a8&gt; . Retraining the Model . I decided to retrain the model from scratch with the full dataset. This time I used fastai&#39;s lr_find method to find a good learning rate by plotting it against the loss function on a mini-epoch. This allows me to use a greater learning rate that will train the model faster and is supposed to have better success in generalising. . final_dls = main_block.dataloaders(final_data, bs=28) . final_learner = cnn_learner(final_dls, resnet50, metrics=accuracy).to_fp16() . final_learner.loss_func = LabelSmoothingCrossEntropy() . final_learner.lr_find() . /usr/local/lib/python3.6/dist-packages/fastai/learner.py:53: UserWarning: Could not load the optimizer state. if with_opt: warn(&#34;Could not load the optimizer state.&#34;) . SuggestedLRs(lr_min=0.004786301031708717, lr_steep=1.5848931980144698e-06) . final_learner.fine_tune(2, 1e-3) . epoch train_loss valid_loss accuracy time . 0 | 0.909822 | 0.777522 | 0.831211 | 28:26 | . epoch train_loss valid_loss accuracy time . 0 | 0.684484 | 0.628349 | 0.896991 | 33:23 | . 1 | 0.609434 | 0.581203 | 0.915895 | 33:22 | . The high learning rate has worked well and the accuracy is 91.58% on the validation set after just three epochs. Now I unfreeze all the layers of the model, calculate a new learning rate and train further. The learning rate function is sloping upward now as the model has already learned all the &#39;low hanging fruit&#39; in its first few epochs. . final_learner.unfreeze() . final_learner.lr_find() . SuggestedLRs(lr_min=9.12010818865383e-08, lr_steep=7.585775847473997e-07) . The additional three epochs of training didn&#39;t seem to do much and the accuracy actually dropped slightly. Although the validation loss went down slightly as well so at least the model probably didn&#39;t do any overfitting on those epochs. . I saved and submitted the model to Kaggle and received a score of 88.5% for this model which marks about a 1% drop in accuracy from the models I built solely on the competition data. This might be because the additional images I found from other sources have some slight differences in them from the competition set which might lower the accuracy slightly on the competition test set. Another reason could be the addition of misclassified images from unlabelled set that I ran inference on. . final_learner.fit_one_cycle(3, lr_max=slice(6e-7, 1e-5), cbs=EarlyStoppingCallback()) . epoch train_loss valid_loss accuracy time . 0 | 0.598469 | 0.590895 | 0.912423 | 33:19 | . 1 | 0.584755 | 0.582810 | 0.912230 | 33:31 | . 2 | 0.592730 | 0.580823 | 0.914931 | 33:24 | . final_learner.save(&#39;final_model&#39;) . Path(&#39;models/final_model.pth&#39;) .",
            "url": "https://toodoi.github.io/datascience/2020/12/08/Cassava.html",
            "relUrl": "/2020/12/08/Cassava.html",
            "date": " • Dec 8, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Stochastic Gradient Descent",
            "content": "!pip install fastai --upgrade . Stochastic Gradient Descent (SGD) is an optimisation algorithm which can be used to minimise a loss function in order to fit a model. This notebook illustrates the process of SGD by using it to train an image classifier from scratch. This example is taken from the fast.ai course. . The MNIST dataset is used which contains images of handwritten numbers from 0 to 9. The problem is to create a model that can correctly predict which digit a given image is. For this example the dataset is restricted to the digits 3 and 7. . from fastai.vision.all import * import seaborn as sns import pandas as pd . Downloading and preparing the dataset . The dataset contains &#39;train&#39; and &#39;valid&#39; folders each of which contain a folder for each of the two classes: 3 and 7. Create a list of tensors from the MNIST data. We have 6,131 3s, and 6,265 7s. . path = untar_data(URLs.MNIST_SAMPLE) Path.BASE_PATH = path . threes = (path/&#39;train&#39;/&#39;3&#39;).ls().sorted() sevens = (path/&#39;train&#39;/&#39;7&#39;).ls().sorted() three_tensors = [tensor(Image.open(o)) for o in threes] seven_tensors = [tensor(Image.open(o)) for o in sevens] len(three_tensors),len(seven_tensors) . (6131, 6265) . Combine all the images of each class into a single three-dimensional tensor and convert the pixel values to floats between 0 and 1. Looking at the shape of the tensor, we have 6,131 images of 3s that are 28 by 28 pixels. . stacked_sevens = torch.stack(seven_tensors).float()/255 stacked_threes = torch.stack(three_tensors).float()/255 stacked_threes.shape . torch.Size([6131, 28, 28]) . Concatenate the separate class tensors into a single tensor train_x to hold all the images for training and create the tensor train_y to hold the training labels or targets (1 for 3s and 0 for 7s). The training images and labels are zipped together in dset because a PyTorch Dataset is required to return a tuple when indexed. Note: the images have been changed from a 28 by 28 matrix to a 28*28 vector (784 column-long row) where each column represents a pixel value. This is important as it enables us to use matrix multiplication between the input data (pixel values) and parameters to produce an output. . train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28) train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1) dset = list(zip(train_x,train_y)) dset[0][0].shape, dset[0][1].shape . (torch.Size([784]), torch.Size([1])) . Create the validation dataset in the same manner . valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;3&#39;).ls()]) valid_3_tens = valid_3_tens.float()/255 valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/&#39;valid&#39;/&#39;7&#39;).ls()]) valid_7_tens = valid_7_tens.float()/255 valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28) valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1) valid_dset = list(zip(valid_x,valid_y)) . We now have two datasets: dset which contains all the training images and their associated labels, and valid_dset which contains all the validation images and their labels. The datasets are a list of tuple pairs where the first item is an image represented as a vector of magnitude 784 and the second item is a label, either 0 or 1. . Building the architecture . The first step is to initialize the parameters. These are the weights or coefficients which will be applied to the data to make class predictions. It is common to initialize the parameters randomly. Create weights, a 784 row vector corresponding to the pixel length of the images, each row has a value randomly initialized using a normal random number distribution which will be applied to the pixel values to predict the class value. bias is a randomly initialised scalar variable which increases flexibility by allowing the output of the linear equations to be non-zero when the input values are 0. . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() weights = init_params((28*28,1)) bias = init_params(1) weights.shape, bias.shape . (torch.Size([784, 1]), torch.Size([1])) . The graph below shows that each of the 784 weights has been given a random value from a standard normal distribution. . wdf = pd.DataFrame(weights) wdf.rename(columns={0 :&#39;weight value&#39;}, inplace=True ) g = sns.catplot(x=wdf.index, y=&#39;weight value&#39;, data=wdf, kind=&#39;bar&#39;) (g.set_axis_labels(&quot;Weights&quot;, &quot;Weight Value&quot;) .set_xticklabels([])) . &lt;seaborn.axisgrid.FacetGrid at 0x7ff25fe9f710&gt; . Define the model . Create a function that takes the image vectors as input and multiplies them by the parameters to produce an output which will be used to predict the class value. This simple function is actually the model and since the parameters are randomly intitialised its output won&#39;t actually have anything to do with what we want. However, once we compare the outputs with our targets and use some loss function to evaluate its performance, we can use SGD to minimise the loss and improve the model. . def linear1(xb): return xb@weights + bias preds = linear1(train_x) preds . tensor([[-9.8383], [-5.7327], [-0.0574], ..., [-2.0469], [-3.5765], [ 3.2822]], grad_fn=&lt;AddBackward0&gt;) . Next we set an arbitrary threshold to predict whether a given image is a 3 or a 7. . thresh = 0.0 corrects = (preds&gt;thresh).float() == train_y corrects.float().mean().item() . 0.3266376256942749 . The graph below shows the distribution of the prediction values for each class value. We can see that our arbitrary threshold of 0 in fact does a very poor job of predicting the class values because there is a healthy mix of both 3s and 7s on either end of 0. These two lovely shaped distributions are to be expected from intialising the weights randomly using the standard normal distribution. . df = pd.DataFrame(preds) df[&#39;threes&#39;] = df[:6131] df[&#39;sevens&#39;] = df[0][6131:] sns.histplot(df[&#39;threes&#39;], color=&quot;skyblue&quot;) sns.histplot(df[&#39;sevens&#39;], color=&quot;lightsalmon&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff25cdf2a58&gt; . Define a loss function . The loss function is a means of assessing the the current weight assignments in terms of actual performance. . This loss function takes the outputs from the linear1 model as inputs and compares them to the targets. It measures the distance of each prediction from its target label (i.e. 1 for 3s and 0 for 7s) for a given batch containing prediction values and target labels and returns an average of these distances. It is our goal to minimise this function by changing the values of the weights. A score of 0 would mean that for some combination of weights applied to a batch of inputs, the model produced outputs that corresponded exactly to the batch&#39;s target labels. . One problem with mnist_loss as currently defined is that it assumes that prediction values are always between 0 and 1 (the above graph shows they are actually ranging from around -20 to 20). The sigmoid method in the loss function transforms the prediction values into values that fall in the domain of 0 to 1 to allow our loss function to work. . . def mnist_loss(predictions, targets): predictions = predictions.sigmoid() return torch.where(targets==1, 1-predictions, predictions).mean() . Creater the dl DataLoader which takes our dataset and turns it into an iterator over many batches. The batchs are tuples of tensors representing batches of images and targets. Here we specify a batch size of 256. Processing the dataset in batches like this is the difference between Gradient Descent and Stochastic Gradient Descent. Gradient Descent requires much more computational resources as the entire dataset needs to be processed for one epoch. . dl = DataLoader(dset, batch_size=256) valid_dl = DataLoader(valid_dset, batch_size=256) . Optimisation . Now that we have a loss function to measure the performance of our model, we need a method that updates the paramaters (weights and bias) to minimise the loss function and improve the model&#39;s performance, this is often referred to as stepping. The goal is to adjust the weights until we find the bottom of the loss function and an efficient method for this is to use the gradient of the loss function to tell us which direction to adjust the weights. . . calc_grad will process our batches through our model and assess performance using the loss function while tracking the gradient for each weight. . def calc_grad(x_batch, y_batch, model): preds = model(x_batch) loss = mnist_loss(preds, y_batch) loss.backward() . Now all that is left is to update the parameters based on the gradients. It is common to multiply the gradient by a small number called the learning rate to control the size of gradient steps. If it is too large, the algorithm could step beyond the minimum and jump around the function a lot. If it is too small, it will take longer to reach the minimum. Often times the learning rate is set through some trial and error. . The full process is represented in the flow chart below and shows how it is an iterative process. We initialise the weights and measure the predictions from a model using a loss function, record the gradients and step the parameters toward the bottom of the loss function. We repeat the process with the stepped parameters and continue iterating to improve the predictions until we decide to stop the process. . . The train_epoch function includes a loop to upgrade the parameters based on the gradients and a learning rate: lr. . def train_epoch(model, lr, params): for x_batch, y_batch in dl: calc_grad(x_batch, y_batch, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . We also want to check how we&#39;re doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it&#39;s greater than 0. The batch_accuracy function does this and returns an accuracy score. validate_epoch then puts all the batches together and returns an overall score for each epoch. . def batch_accuracy(x_batch, y_batch): preds = x_batch.sigmoid() correct = (preds&gt;0.5) == y_batch return correct.float().mean() def validate_epoch(model): accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl] return round(torch.stack(accs).mean().item(), 4) . Now all thats left is to train the model. First we&#39;ll run three epochs and see how the accuracy improves and look at how the distribution of class values (targets) changes. The accuracy improves rapidly in just three epochs and we receive accuracy scores of 52.28%, 65.23% and 85%. . lr = 1. params = weights, bias for i in range(3): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.5228 0.6523 0.85 . The graph below shows the distributions of the predictions of the class values being pulled away from each other. . preds = linear1(train_x) df = pd.DataFrame(preds) df[&#39;threes&#39;] = df[:6131] df[&#39;sevens&#39;] = df[0][6131:] sns.histplot(df[&#39;threes&#39;], color=&quot;skyblue&quot;) sns.histplot(df[&#39;sevens&#39;], color=&quot;lightsalmon&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff26081e898&gt; . After 15 more epochs the accuracy improves to over 97% . for i in range(15): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.9242 0.9501 0.957 0.9609 0.9628 0.9648 0.9657 0.9682 0.9687 0.9691 0.9696 0.9701 0.9701 0.9701 0.9701 . We can also see the how the current combination of weights produces predictions which divide the class values into two distinct groups compared to the starting randomly initialised weights. The predictions of images of 7s which intially had a greater mean than the predictions of 3s has been pulled to the left into larger negative values. This is because large negative values are converted to 0 or very close to 0 by the sigmoid function. Since we set the target for 7s to 0, the weights have been optimised to the point where the model will produce large negative prediction values for images of 7s which corresponds to its target label of 0. Likewise the model will produce large positive prediction values for 3s which corresponds to its target label of 1 once the sigmoid function is applied. . preds = linear1(train_x) df = pd.DataFrame(preds) df[&#39;threes&#39;] = df[:6131] df[&#39;sevens&#39;] = df[0][6131:] sns.histplot(df[&#39;threes&#39;], color=&quot;skyblue&quot;) sns.histplot(df[&#39;sevens&#39;], color=&quot;lightsalmon&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff25d355668&gt; . Distribution of predictions using randomly initialised weights .",
            "url": "https://toodoi.github.io/datascience/2020/11/15/SGD.html",
            "relUrl": "/2020/11/15/SGD.html",
            "date": " • Nov 15, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! My name’s Todd. I used to work in economic and public policy and have always had a deep interest in data and programming. After returning back to Australia earlier than anticipated due to Coronavirus, I’ve had the opportunity to expand on my programming and statistics skills and make the career shift into data science which I am very passionate about. I am currently studying full time and looking for employment opportunities in the area of data science or any other jobs where I can use data driven techniques to solve problems. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://toodoi.github.io/datascience/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://toodoi.github.io/datascience/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}